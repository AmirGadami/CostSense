# ğŸ’¸ CostSense

**CostSense** is a fine-tuned GPT-based AI system that estimates the prices of consumer items based on textual descriptions. It leverages a Hugging Face dataset and OpenAIâ€™s `gpt-4o-mini` model to deliver precise price predictions with no extra explanationsâ€”just numbers.

---

## ğŸš€ Features

- ğŸ§  Fine-tuned on a **Hugging Face dataset** for realistic item pricing  
- ğŸ”¬ Uses **OpenAIâ€™s `gpt-4o-mini` (July 2024)** for high-quality predictions  
- ğŸ—ƒï¸ Automatic formatting to OpenAI-compatible JSONL  
- ğŸ“¦ Modular and reusable architecture with `Item` and `Tester` utilities  
- ğŸ“ˆ Evaluation and visualizations for model performance  
- ğŸ§ª Weights & Biases integration for training tracking  

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ gpt_model.ipynb              # Interactive testing of base or fine-tuned models
â”œâ”€â”€ fine_tuned_gpt.ipynb         # End-to-end fine-tuning workflow
â”œâ”€â”€ items.py                     # Item class: handles prompt formatting
â”œâ”€â”€ loaders.py                   # Data loading from Hugging Face dataset
â”œâ”€â”€ testing.py                   # Performance metrics and evaluation
â”œâ”€â”€ environment.yml              # Conda environment definition
â”œâ”€â”€ train.pkl                    # Preprocessed training data
â”œâ”€â”€ test.pkl                     # Preprocessed testing data
â”œâ”€â”€ fine_tune_train.jsonl        # Training data for OpenAI fine-tuning
â”œâ”€â”€ fine_tune_validation.jsonl   # Validation data for OpenAI fine-tuning
```

---

## âš™ï¸ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/CostSense.git
cd CostSense
```

### 2. Create the Environment

```bash
conda env create -f environment.yml
conda activate llms
```

### 3. Set Environment Variables

Create a `.env` file in the root directory:

```env
HF_TOKEN=your_huggingface_token
OPENAI_API_KEY=your_openai_api_key
```

---

## ğŸ“Š Dataset

CostSense uses a **Hugging Face dataset** containing item descriptions and ground truth prices. It is preprocessed and stored as `train.pkl` and `test.pkl`. You can easily replace it with your own dataset using the format defined in `items.py`.

---

## ğŸ§ª Fine-Tuning & Evaluation

### Run the fine-tuning pipeline:
- Load and split your dataset  
- Convert to OpenAI's JSONL format  
- Upload data via OpenAI's API  
- Fine-tune using `gpt-4o-mini-2024-07-18`  
- Retrieve your model and evaluate it on test items  

### Evaluate model accuracy:

```python
Tester.test(gpt_fine_tuned, test)
```

---

## ğŸ“¤ Example Prompt

```json
[
  {"role": "system", "content": "You estimate prices of items. Reply only with the price, no explanation"},
  {"role": "user", "content": "A high-resolution 27-inch 4K monitor with adjustable stand and HDMI support."}
]
```

**Expected Output**:
```
Price is $329.00
```

---

## ğŸ§° Tech Stack

- **OpenAI** (`gpt-4o-mini`)
- **Hugging Face Hub** (datasets, token management)
- **Weights & Biases** (optional integration)
- **Transformers**, **LangChain**, **Gradio**
- **Python**, **Jupyter**, **FAISS**, **dotenv**

---

## ğŸ§  Use Cases

- E-commerce product valuation  
- Retail market analysis  
- Intelligent chatbots that estimate costs  
- Pricing prediction for recommendation systems  

---

## ğŸ“¬ Contact

**Amir Ghadami**  
ğŸ“§ [ah.ghadami75@gmail.com](mailto:ah.ghadami75@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/amirhosseinghadami/) | ğŸ¦ [Twitter/X](https://x.com/Amir_ghadamii) | ğŸ’» [GitHub](https://github.com/amirgadami)